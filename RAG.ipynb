{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b92977-53d3-4664-b3a6-5239db3bac71",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "檢索增強生成<br/>\n",
    "難易度：★★☆☆☆<br/>\n",
    "[文章傳送門](https://github.com/Sakuard/bootcamp_ai/blob/main/doc/LLMxNLPxRAG.md)\n",
    "\n",
    "\n",
    "### RAG 基本原理\n",
    "![Basic RAG Structure](./src/rag/basic_rag_structure.png)\n",
    "### 分別為\n",
    "- 資料嵌入(Embedding) #藍色路徑\n",
    "- 資料檢索 ##黃色路徑\n",
    "\n",
    "#### 資料嵌入\n",
    "1. 透過把資料 ***Embedding***\n",
    "2. 將 ***Embedding*** 結果存到 ***向量資料庫*** 來建立**個人知識庫**\n",
    "#### 資料檢索\n",
    "1. 使用者提出提問 (Query)\n",
    "2. 把 Query Embedding\n",
    "3. 把 Query Embedding 結果給 ***向量資料庫*** 做比對，找到最相似的資料後回傳\n",
    "4. 將 Query + 回傳資料, 做 Prompt 整合給 LLM 產生回應\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a24368-3859-453e-93f0-c04c0b58a518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "!pip install ollama chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8150826-9ce7-422d-8539-5e8d622fe461",
   "metadata": {},
   "source": [
    "documents 即為我們的模擬資料<br/>並把 embedding 的結果儲存到 chromadb<br/>這邊 embedding-model 使用 mxbai-embed-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1b6dca-957a-400e-9c98-018870f75151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "# collection exits ? use it || create one\n",
    "try:\n",
    "    collection = client.create_collection(name=\"docs\")\n",
    "except Exception as e:\n",
    "    if \"Collection docs already exists\" in str(e):\n",
    "        collection = client.get_collection(name=\"docs\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# ID check\n",
    "existing_docs = collection.get()\n",
    "existing_ids = set(existing_docs['ids'])\n",
    "\n",
    "# Document vectorize and store into vector database中\n",
    "for i, d in enumerate(documents):\n",
    "    if str(i) in existing_ids:\n",
    "        print(f\"ID {i} already exists, skipping.\")\n",
    "        continue\n",
    "\n",
    "    response = ollama.embeddings(model=\"mxbai-embed-large\", prompt=d)\n",
    "    embedding = response[\"embedding\"]\n",
    "    collection.add(\n",
    "        ids=[str(i)],\n",
    "        embeddings=[embedding],\n",
    "        documents=[d]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8857f-100d-4712-89ef-1a05b93fd3d6",
   "metadata": {},
   "source": [
    "使用者 Query 提問<br/>把 Query embedding，將結果給 chromadb 做比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b91b59-e300-4f03-ba39-1a86079fbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"What animals are llamas related to?\"\n",
    "\n",
    "# vectorinze and embeddings\n",
    "response = ollama.embeddings(\n",
    "  prompt=Query,\n",
    "  model=\"mxbai-embed-large\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "  n_results=1\n",
    ")\n",
    "data = results['documents'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5eaff-c50c-4d09-9e4b-855de1c5923d",
   "metadata": {},
   "source": [
    "用 chromadb 比對結果 {data} 與使用者提問 {Query} 整合成一個 prompt<br/>給 LLM-{llama2} 產生回應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78507030-27c3-4918-a60b-60888e86097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llamas are members of the camelid family, which means they are closely related to other animals such as:\n",
      "\n",
      "1. Vicuñas: Vicuñas are small, wild relatives of llamas and alpacas. They are found in the Andean highlands and are known for their soft, woolly coats.\n",
      "2. Camels: As mentioned earlier, llamas are part of the camelid family, which means they are closely related to camels. Camels are large, even-toed ungulates that are native to Africa and Asia.\n",
      "3. Alpacas: Alpacas are domesticated mammals that are similar to llamas but have a different coat type. They are also members of the camelid family and are found in South America.\n",
      "\n",
      "In summary, llamas are related to vicuñas, camels, and alpacas through their shared membership in the camelid family.\n"
     ]
    }
   ],
   "source": [
    "ollama.pull(model=\"llama2\")\n",
    "# response\n",
    "output = ollama.generate(\n",
    "  model=\"llama2\",\n",
    "  prompt=f\"Using this data: {data}. Respond to this prompt: {Query}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
